{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Constants*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "\n",
    "SIM_COUNT = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Tests\n",
    "This notebook is a summary of the most common statistical tests used in data science. The goal is to provide a quick reference for the most common tests and when to use them. Each test has a brief explanation detailing its assumptions, null hypothesis, and when to use it. There will also be a code implementation of each test using Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Z-Test](#z-test)\n",
    "2. [Formulas](#formulas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-Test\n",
    "A z-test is a statistical test used to determine whether there is a significant difference between a sample mean and population mean or a sample proportion and a population proportion. It assumes normality, meaning that the popoulation from which the sample is drawn should be normally distributed, or if working with proportions, the sample size should be large enough. The population variance should also be known or estimated well. If working with proportions, the sample size should be large enough to ensure that the sample proportion is normally distributed. The z-score measures how many standard deviations the observed sample value is from the hypothesized population value. The critical value for a $0.05$ significance level is $\\pm 1.96$. If the z-score is greater than $1.96$ or less than $-1.96$, then the null hypothesis can be rejected.\n",
    "\n",
    "$$z = \\frac{\\hat{p} - p_0}{\\text{Standard Error}}$$\n",
    "\n",
    "$$z = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}}$$\n",
    "\n",
    "### Hypotheses\n",
    "$H_0 : p = p_0$\n",
    "\n",
    "The assumption that there is no significant differenct between the sample mean/proportion and the population mean/proportion. Typically, the null hypothese states that the sample mean/proportion is equal to the population mean/proportion. \n",
    "\n",
    "$H_A : p \\neq p_0$\n",
    "\n",
    "The alternative hypothesis states that the sample mean/proportion is different from the population mean/proportion. One-tailed tests can also be used to determine if the sample mean/proportion is greater or less than the population mean/proportion.\n",
    "### Use\n",
    "- For large sample sizes ($n > 30$).\n",
    "- When the variance/standard deviation of the population is known (or can be estimated well).\n",
    "- For proportion testing when comparing an observed proportion to a hypothesized proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.303314829119355, 1.6826148341975156e-05)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ztest_proportion(obs, exp, n):\n",
    "    z = (obs - exp) / math.sqrt(obs* (1 - obs) / n)\n",
    "    p = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "    return z, p\n",
    "\n",
    "ztest_proportion(0.4, 1/3, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulas\n",
    "- **Mean**: $$\\mu = \\frac{\\sum_{i=1}^{n} x_i}{n}$$\n",
    "- **Variance**: $$\\sigma^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\mu)^2}{n}$$\n",
    "- **Standard Deviation**: $$\\sigma = \\sqrt{\\sigma^2}$$\n",
    "- **Covariance**: $$Cov(X, Y) = \\frac{\\sum_{i=1}^{n} (x_i - \\mu_x) * (y_i - \\mu_y)}{n}$$\n",
    "- **Correlation**: $$Corr(X, Y) = \\frac{Cov(X, Y)}{\\sigma_x * \\sigma_y}$$\n",
    "- **Least Squares Regression Line**: $$y = mx + b$$\n",
    "- **Least Squares Regression Slope**: $$m = \\frac{\\sum_{i=1}^{n} (x_i - \\mu_x) * (y_i - \\mu_y)}{\\sum_{i=1}^{n} (x_i - \\mu_x)^2}$$\n",
    "- **Least Squares Regression Intercept**: $$b = \\mu_y - m * \\mu_x$$\n",
    "- **Least Squares Regression Line Prediction**: $$\\hat{y} = m * x + b$$\n",
    "- **Least Squares Regression Line Residual**: $$e = y - \\hat{y}$$\n",
    "- **Least Squares Regression Line Residual Sum of Squares**: $$RSS = \\sum_{i=1}^{n} e_i^2$$\n",
    "- **Least Squares Regression Line Total Sum of Squares**: $$TSS = \\sum_{i=1}^{n} (y_i - \\mu_y)^2$$\n",
    "- **Least Squares Regression Line Explained Sum of Squares**: $$ESS = \\sum_{i=1}^{n} (\\hat{y_i} - \\mu_y)^2$$\n",
    "- **Least Squares Regression Line R-Squared**: $$R^2 = \\frac{ESS}{TSS} = 1 - \\frac{RSS}{TSS}$$\n",
    "- **Least Squares Regression Line Standard Error**: $$SE = \\sqrt{\\frac{RSS}{n-2}}$$\n",
    "- **Least Squares Regression Line Confidence Interval**: $$CI = m \\pm t_{\\alpha/2} * SE$$\n",
    "- **Least Squares Regression Line Prediction Interval**: $$PI = \\hat{y} \\pm t_{\\alpha/2} * SE$$\n",
    "- **Least Squares Regression Line Hypothesis Test**: $$t = \\frac{m - 0}{SE}$$\n",
    "- **Least Squares Regression Line Hypothesis Test P-Value**: $$P = 2 * (1 - t_{n-2})$$\n",
    "- **Least Squares Regression Line Hypothesis Test Confidence Interval**: $$CI = m \\pm t_{n-2} * SE$$\n",
    "- **Least Squares Regression Line Hypothesis Test Prediction Interval**: $$PI = \\hat{y} \\pm t_{n-2} * SE$$\n",
    "- **Least Squares Regression Line Hypothesis Test F-Statistic**: $$F = \\frac{ESS/k}{RSS/(n-k-1)}$$\n",
    "- **Least Squares Regression Line Hypothesis Test F-Statistic P-Value**: $$P = 1 - F_{n-k-1, k}$$\n",
    "- **Least Squares Regression Line Hypothesis Test F-Statistic Confidence Interval**: $$CI = \\frac{1}{F_{k, n-k-1}}$$\n",
    "- **Least Squares Regression Line Hypothesis Test F-Statistic Prediction Interval**: $$PI = \\frac{1}{F_{k, n-k-1}}$$\n",
    "- **Least Squares Regression Line Hypothesis Test Chi-Squared Statistic**: $$\\chi^2 = \\frac{n * R^2}{1 - R^2}$$\n",
    "- **Least Squares Regression Line Hypothesis Test Chi-Squared Statistic P-Value**: $$P = 1 - \\chi^2_{1, n-2}$$\n",
    "- **Least Squares Regression Line Hypothesis Test Chi-Squared Statistic Confidence Interval**: $$CI = \\frac{1}{\\chi^2_{n-2, 1}}$$\n",
    "- **Least Squares Regression Line Hypothesis Test Chi-Squared Statistic Prediction Interval**: $$PI = \\frac{1}{\\chi^2_{n-2, 1}}$$\n",
    "- **Least Squares Regression Line Hypothesis Test Z-Statistic**: $$Z = \\frac{m - 0}{SE}$$\n",
    "- **Least Squares Regression Line Hypothesis Test Z-Statistic P-Value**: $$P = 2 * (1 - Z)$$\n",
    "- **Least Squares Regression Line Hypothesis Test Z-Statistic Confidence Interval**: $$CI = m \\pm Z$$\n",
    "- **Least Squares Regression Line Hypothesis Test Z-Statistic Prediction Interval**: $$PI = \\hat{y} \\pm Z$$\n",
    "- **Least Squares Regression Line Hypothesis Test T-Statistic**: $$T = \\frac{m - 0}{SE}$$\n",
    "- **Least Squares Regression Line Hypothesis Test T-Statistic P-Value**: $$P = 2 * (1 - T_{n-2})$$\n",
    "- **Least Squares Regression Line Hypothesis Test T-Statistic Confidence Interval**: $$CI = m \\pm T_{n-2} * SE$$\n",
    "- **Least Squares Regression Line Hypothesis Test T-Statistic Prediction Interval**: $$PI = \\hat{y} \\pm T_{n-2} * SE$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
